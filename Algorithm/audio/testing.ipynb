{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paraformer-zh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "from funasr import AutoModel\n",
    "from funasr.utils.postprocess_utils import rich_transcription_postprocess\n",
    "\n",
    "# Audio settings\n",
    "SAMPLE_RATE = 16000\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "CHUNK_MS = 2500  # 2.5 seconds per chunk\n",
    "CHUNK_SIZE = int(SAMPLE_RATE * CHUNK_MS / 1000)\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=SAMPLE_RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "funasr version: 1.2.6.\n",
      "Check update of funasr, and it would cost few times. You may disable it by set `disable_update=True` in AutoModel\n",
      "You are using the latest version of funasr-1.2.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-07 18:25:13,879 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "2025-04-07 18:25:17,353 - modelscope - INFO - Use user-specified model revision: v2.0.4\n",
      "2025-04-07 18:25:17,956 - modelscope - INFO - Use user-specified model revision: v2.0.4\n"
     ]
    }
   ],
   "source": [
    "model = AutoModel(model=\"paraformer-zh\", model_revision=\"v2.0.4\",\n",
    "                  vad_model=\"fsmn-vad\", vad_model_revision=\"v2.0.4\",\n",
    "                  punc_model=\"ct-punc-c\", punc_model_revision=\"v2.0.4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real-time speech recognition started. Press Ctrl+C to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.031: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  7.16it/s]                                                                                          \n",
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]\n",
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 25.88it/s]                                                                                          \n",
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]\n",
      "rtf_avg: 0.005: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 41.33it/s]                                                                                          \n",
      "rtf_avg: 0.862: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.13it/s]\n",
      "rtf_avg: -0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 100.00it/s]\n",
      "rtf_avg: 0.107, time_speech:  4.500, time_escape: 0.483: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  2.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  My birthday.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.006: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 33.26it/s]                                                                                          \n",
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]\n",
      "rtf_avg: 0.003: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 66.67it/s]                                                                                          \n",
      "rtf_avg: 0.105: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.04it/s]\n",
      "rtf_avg: -0.024: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 37.64it/s]\n",
      "rtf_avg: 0.080, time_speech:  4.500, time_escape: 0.360: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  2.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  I want to dist, whether she just working or not working.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.015: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 13.87it/s]                                                                                          \n",
      "rtf_avg: 0.074: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.23it/s]\n",
      "rtf_avg: -0.031: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 31.06it/s]\n",
      "rtf_avg: 0.078, time_speech:  4.500, time_escape: 0.349: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  2.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  I'm not getting any transcription. Ok你好，我叫泰华。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.006: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 35.63it/s]                                                                                          \n",
      "rtf_avg: 0.123: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.73it/s]\n",
      "rtf_avg: -0.046: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 20.09it/s]\n",
      "rtf_avg: 0.072, time_speech:  4.500, time_escape: 0.322: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: 我会去珍为你一点点。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 18.10it/s]                                                                                          \n",
      "rtf_avg: 0.069: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.31it/s]\n",
      "rtf_avg: -0.004: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 166.66it/s]\n",
      "rtf_avg: 0.069, time_speech:  4.500, time_escape: 0.312: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: 你好在上次现在我现在上次这个我。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.003: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 66.67it/s]                                                                                          \n",
      "rtf_avg: 0.066: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.35it/s]\n",
      "rtf_avg: -0.030: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 32.04it/s]\n",
      "rtf_avg: 0.074, time_speech:  4.500, time_escape: 0.334: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  2.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  I think it's not good, you know, was i.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.003: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 63.23it/s]                                                                                          \n",
      "rtf_avg: 0.066: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.30it/s]\n",
      "rtf_avg: -0.060: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 16.14it/s]\n",
      "rtf_avg: 0.082, time_speech:  4.500, time_escape: 0.371: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: 英文可以，我也可以。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.006: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 35.15it/s]                                                                                          \n",
      "rtf_avg: 0.112: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.20it/s]\n",
      "rtf_avg: -0.021: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 44.21it/s]\n",
      "rtf_avg: 0.075, time_speech:  4.500, time_escape: 0.339: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  2.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: 成文不高，英文英文就比较。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.003: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 71.43it/s]                                                                                          \n",
      "rtf_avg: 0.075: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.94it/s]\n",
      "rtf_avg: -0.021: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 42.89it/s]\n",
      "rtf_avg: 0.082, time_speech:  4.500, time_escape: 0.368: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  2.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: 嗯，你好你好。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 23.19it/s]                                                                                          \n",
      "rtf_avg: 0.075: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  2.94it/s]\n",
      "rtf_avg: -0.035: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 26.65it/s]\n",
      "rtf_avg: 0.085, time_speech:  4.500, time_escape: 0.381: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  And in you speak chinese or the chinese, not local mandon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.003: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 60.45it/s]                                                                                          \n",
      "rtf_avg: 0.104: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.24it/s]\n",
      "rtf_avg: -0.013: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 68.49it/s]\n",
      "rtf_avg: 0.073, time_speech:  4.500, time_escape: 0.328: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  A starard绿色。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 22.87it/s]                                                                                          \n",
      "rtf_avg: 0.064: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.44it/s]\n",
      "rtf_avg: -0.030: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 30.68it/s]\n",
      "rtf_avg: 0.073, time_speech:  4.500, time_escape: 0.328: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: 呃，这个这个好像不行是吧？呃，录不上看。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 24.64it/s]                                                                                          \n",
      "rtf_avg: 0.063: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.51it/s]\n",
      "rtf_avg: -0.038: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 24.59it/s]\n",
      "rtf_avg: 0.073, time_speech:  4.500, time_escape: 0.330: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: 看能不能翻译出来啊，你看这个可以啊啊。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.006: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 35.56it/s]                                                                                          \n",
      "rtf_avg: 0.211: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.55it/s]\n",
      "rtf_avg: -0.060: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 16.02it/s]\n",
      "rtf_avg: 0.078, time_speech:  4.500, time_escape: 0.349: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  2.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized: 好。\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.015: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 14.08it/s]                                                                                          \n",
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]\n",
      "rtf_avg: 0.010: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 22.23it/s]                                                                                          \n",
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]\n",
      "rtf_avg: 0.003: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 74.03it/s]                                                                                          \n",
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]\n",
      "rtf_avg: 0.008: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 33.77it/s]                                                                                          \n",
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]\n",
      "rtf_avg: 0.006: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 35.32it/s]                                                                                          \n",
      "rtf_avg: 0.202: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.08it/s]\n",
      "rtf_avg: -0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 62.10it/s]\n",
      "rtf_avg: 0.059, time_speech:  4.500, time_escape: 0.267: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  Standards is.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.014: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 15.32it/s]                                                                                          \n",
      "rtf_avg: 0.078: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.29it/s]\n",
      "rtf_avg: -0.041: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 22.89it/s]\n",
      "rtf_avg: 0.078, time_speech:  4.500, time_escape: 0.353: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  2.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  But local is not good. Yes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.003: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 71.37it/s]                                                                                          \n",
      "rtf_avg: 0.203: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.05it/s]\n",
      "rtf_avg: -0.012: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 71.05it/s]\n",
      "rtf_avg: 0.059, time_speech:  4.500, time_escape: 0.265: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  Hello, ok, thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.005: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 41.61it/s]                                                                                          \n",
      "rtf_avg: 0.073: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.76it/s]\n",
      "rtf_avg: -0.047: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 20.36it/s]\n",
      "rtf_avg: 0.071, time_speech:  4.500, time_escape: 0.320: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  I am dressing the model, see the response of the model and.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.006: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 35.32it/s]                                                                                          \n",
      "rtf_avg: 0.234: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.38it/s]\n",
      "rtf_avg: -0.022: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 42.98it/s]\n",
      "rtf_avg: 0.057, time_speech:  4.500, time_escape: 0.258: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  Taking final.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.003: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 64.08it/s]                                                                                          \n",
      "rtf_avg: 0.055: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  4.03it/s]\n",
      "rtf_avg: -0.020: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 44.95it/s]\n",
      "rtf_avg: 0.061, time_speech:  4.500, time_escape: 0.276: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  Languages is pretty good. But if i talk about the local language is not.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.009: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 23.17it/s]                                                                                          \n",
      "rtf_avg: 0.212: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00,  3.53it/s]\n",
      "rtf_avg: -0.036: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 25.34it/s]\n",
      "rtf_avg: 0.073, time_speech:  4.500, time_escape: 0.327: 100%|\u001b[31m██████████\u001b[0m| 1/1 [00:00<00:00,  3.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognized:  So i have to find it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "rtf_avg: 0.004: 100%|\u001b[34m██████████\u001b[0m| 1/1 [00:00<00:00, 48.09it/s]                                                                                          \n",
      "  0%|\u001b[31m          \u001b[0m| 0/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stopping...\n"
     ]
    }
   ],
   "source": [
    "# Audio settings\n",
    "SAMPLE_RATE = 16000\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "CHUNK_MS = 4500  # 2.5 seconds per chunk\n",
    "CHUNK_SIZE = int(SAMPLE_RATE * CHUNK_MS / 1000)\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=SAMPLE_RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Real-time speech recognition started. Press Ctrl+C to stop.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Read audio chunk from microphone\n",
    "        audio_data = stream.read(CHUNK_SIZE, exception_on_overflow=False)\n",
    "        \n",
    "        # Convert to bytes-like object (if needed by the model)\n",
    "        audio_16KHz = bytes(audio_data)\n",
    "        \n",
    "        # Process the audio\n",
    "        res = model.generate(\n",
    "            input=audio_16KHz,\n",
    "            cache={},\n",
    "            language=\"zn\",\n",
    "            use_itn=True,\n",
    "            batch_size_s=60,\n",
    "            merge_vad=True,\n",
    "            merge_length_s=15,\n",
    "        )\n",
    "        \n",
    "        # Get and print the transcription\n",
    "        text = res[0][\"text\"]\n",
    "        if text.strip():  # Only print if there's actual text\n",
    "            print(\"Recognized:\", text)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopping...\")\n",
    "finally:\n",
    "    # Clean up\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dolphin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dolphin\n",
    "import os\n",
    "\n",
    "# Set FFmpeg path explicitly\n",
    "os.environ[\"PATH\"] += os.pathsep + r\"D:\\ffmpeg-2025-03-31-git-35c091f4b7-full_build\\ffmpeg-2025-03-31-git-35c091f4b7-full_build\\bin\"\n",
    "waveform = dolphin.load_audio(r\"D:\\jincheng_project\\whisper_model\\dolphin\\test_audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exists: True\n"
     ]
    }
   ],
   "source": [
    "import dolphin\n",
    "from pathlib import Path\n",
    "\n",
    "# Verify the model file exists\n",
    "model_path = r\"D:\\jincheng_project\\whisper_model\\dolphin\\dolphin-small\"\n",
    "print(f\"Model exists: {Path(model_path).exists()}\")  # Should print True\n",
    "\n",
    "# Try loading with absolute path\n",
    "model = dolphin.load_model(\n",
    "    model_name=\"small\",\n",
    "    model_dir=model_path,  # Use full path to the .pt file\n",
    "    device=\"cuda\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\jincheng_project\\whisper_model\\dolphin\\t\\lib\\site-packages\\espnet2\\s2t\\espnet_model.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    }
   ],
   "source": [
    "result = model(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zh><CN><asr><0.00> 那是看我就说我运气很好吧这一次抽到二二三的人我们亲亲<30.00>\n"
     ]
    }
   ],
   "source": [
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zh><CN><asr><0.00> 那是看我就说我运气很好吧这一次抽到二二三的人我们亲亲<30.00>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Specify language and region\n",
    "result = model(waveform, lang_sym=\"zh\", region_sym=\"CN\")\n",
    "print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model exists: True\n",
      "Real-time speech recognition started. Press Ctrl+C to stop.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\jincheng_project\\whisper_model\\dolphin\\t\\lib\\site-packages\\espnet2\\s2t\\espnet_model.py:279: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(False):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<zh><CN><asr><0.00> 对。<2.50>\n",
      "<zh><CN><asr><0.00> 啊。<2.50>\n",
      "\n",
      "Stopping...\n"
     ]
    }
   ],
   "source": [
    "import dolphin\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "# Verify the model file exists\n",
    "model_path = r\"D:\\jincheng_project\\whisper_model\\dolphin\\dolphin-small\"\n",
    "print(f\"Model exists: {Path(model_path).exists()}\")  # Should print True\n",
    "\n",
    "# Try loading with absolute path\n",
    "model = dolphin.load_model(\n",
    "    model_name=\"small\",\n",
    "    model_dir=model_path,  # Use full path to the .pt file\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "# Audio settings\n",
    "SAMPLE_RATE = 16000\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "CHUNK_MS = 2500  # 2.5 seconds per chunk\n",
    "CHUNK_SIZE = int(SAMPLE_RATE * CHUNK_MS / 1000)\n",
    "\n",
    "# Initialize PyAudio\n",
    "p = pyaudio.PyAudio()\n",
    "stream = p.open(format=FORMAT,\n",
    "                channels=CHANNELS,\n",
    "                rate=SAMPLE_RATE,\n",
    "                input=True,\n",
    "                frames_per_buffer=CHUNK_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Real-time speech recognition started. Press Ctrl+C to stop.\")\n",
    "\n",
    "try:\n",
    "    while True:\n",
    "        # Read audio chunk from microphone\n",
    "        audio_data = stream.read(CHUNK_SIZE, exception_on_overflow=False)\n",
    "        \n",
    "        # Convert to bytes-like object (if needed by the model)\n",
    "        audio_16KHz = bytes(audio_data)\n",
    "        audio_array = np.frombuffer(audio_data, dtype=np.int16).astype(np.float32) / 32768.0\n",
    "        res = model(audio_array, lang_sym=\"zh\", region_sym=\"CN\")\n",
    "        print(res.text)\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nStopping...\")\n",
    "finally:\n",
    "    # Clean up\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    p.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
